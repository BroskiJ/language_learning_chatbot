# -------------------------------------------------------------------------
# gemini_service.py - Google Gemini AI Integration Services
# -------------------------------------------------------------------------
# This module provides services for interacting with the Google Gemini AI
# language model to power language learning conversations. It handles 
# tasks like conversation management, message correction, and linguistic analysis.
# -------------------------------------------------------------------------

# Standard library imports
import logging
import os

# Flask imports
from flask import session

# Google Generative AI imports
import google.generativeai as genai

# LangChain imports
from langchain.memory import ConversationBufferMemory
from langchain.schema import HumanMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI

# Configure module logger
logger = logging.getLogger(__name__)

# Load the Google Gemini API key from environment variables
# This is the only source for the API key - no client-side API key management
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")

# Dictionary to store conversation memories for each user/guest session
# Keys are session IDs, values are ConversationBufferMemory instances
# This maintains conversation history between API calls without a database
conversation_memories = {}

def clear_conversation_memory(conversation_id):
    """
    Clear the conversation memory for a specific user or session
    
    Args:
        conversation_id: The unique identifier for the conversation
        
    Returns:
        bool: True if memory was cleared, False if conversation_id not found
    """
    if conversation_id in conversation_memories:
        # Remove the conversation memory
        del conversation_memories[conversation_id]
        logger.debug(f"Cleared conversation memory for conversation_id: {conversation_id}")
        return True
    else:
        logger.debug(f"No conversation memory found for conversation_id: {conversation_id}")
        return False

def get_welcome_message(language):
    """
    Generate a welcome message in the specified language to start the conversation.
    
    This function attempts to generate a natural-sounding greeting in the target language
    using the Gemini AI model. If the API call fails or no API key is available, it falls
    back to predefined welcome messages for common languages.
    
    The function uses two approaches for generation:
    1. Direct API call to Gemini (preferred for better results)
    2. LangChain integration as a fallback
    
    Args:
        language (str): The target language (e.g., "Spanish", "French")
    
    Returns:
        str: A welcome message in the target language, either generated by the LLM
             or selected from predefined fallback messages
    """
    api_key = GEMINI_API_KEY
    
    if not api_key:
        logger.warning("API key not found, using fallback welcome message")
        # Fallback welcome messages if API key not available
        welcome_messages = {
            "Spanish": "¡Hola! Soy tu tutor de español. ¿Cómo estás hoy?",
            "French": "Bonjour! Je suis votre tuteur de français. Comment allez-vous aujourd'hui?",
            "German": "Hallo! Ich bin dein Deutschlehrer. Wie geht es dir heute?",
            "Italian": "Ciao! Sono il tuo tutor di italiano. Come stai oggi?",
            "Portuguese": "Olá! Sou seu tutor de português. Como você está hoje?",
            "Russian": "Привет! Я твой репетитор по русскому языку. Как дела сегодня?",
            "Japanese": "こんにちは！私はあなたの日本語チューターです。今日の調子はどうですか？",
            "Chinese": "你好！我是你的中文导师。今天感觉如何？",
            "Korean": "안녕하세요! 저는 당신의 한국어 튜터입니다. 오늘 기분이 어떠세요?"
        }
        
        return welcome_messages.get(language, f"Hello! I'm your {language} tutor. How are you today?")
    
    try:
        # Generate a different welcome message each time using the LLM
        # This prompt is carefully constructed to:
        # 1. Create a natural, native-sounding greeting
        # 2. Keep the output simple for beginners to understand
        # 3. Ensure consistent formatting of the response
        system_message = f"""You are a friendly language tutor.
        Generate a short, friendly greeting in {language}.
        Keep it simple and casual - something a native speaker would say when meeting someone.
        The response should ONLY be the greeting in {language}, nothing else.
        Maximum 15 words."""
        
        # IMPLEMENTATION APPROACH 1: Direct API call to Gemini
        # This is the preferred method for simplicity and reliability
        try:
            # Configure the Gemini API with the user's API key
            genai.configure(api_key=api_key)
            # Use the newer Gemini 1.5 Flash model for faster responses
            model = genai.GenerativeModel('gemini-1.5-flash')
            # Generate content and extract text from the response
            response = model.generate_content(system_message).text
            logger.info("Used direct API call for welcome message")
            # Clean up the response by removing extra whitespace
            return response.strip()
            
        except Exception as e:
            # Log failure for debugging purposes
            logger.warning(f"Direct API failed for welcome message: {str(e)}")
            
            # IMPLEMENTATION APPROACH 2: LangChain integration
            # This is used as a fallback if the direct API call fails
            # LangChain provides more structured handling of prompts and responses
            llm = ChatGoogleGenerativeAI(
                model="gemini-1.5-flash", 
                api_key=api_key,
                temperature=0.7  # Slightly randomized to get varied greetings
            )
            
            # Create a system message that the model will respond to
            result = llm.invoke([SystemMessage(content=system_message)])
            
            # LangChain response handling: extract content from the response object
            # Different LangChain versions may return different response formats
            if hasattr(result, 'content'):
                return result.content.strip()
            else:
                # Fallback to string representation if content attribute isn't available
                return str(result).strip()
            
    except Exception as e:
        logger.error(f"Error generating welcome message: {str(e)}")
        # Fallback to default messages on error
        welcome_messages = {
            "Spanish": "¡Hola! Soy tu tutor de español. ¿Cómo estás hoy?",
            "French": "Bonjour! Je suis votre tuteur de français. Comment allez-vous aujourd'hui?",
            "German": "Hallo! Ich bin dein Deutschlehrer. Wie geht es dir heute?",
            "Italian": "Ciao! Sono il tuo tutor di italiano. Come stai oggi?",
            "Portuguese": "Olá! Sou seu tutor de português. Como você está hoje?",
            "Russian": "Привет! Я твой репетитор по русскому языку. Как дела сегодня?",
            "Japanese": "こんにちは！私はあなたの日本語チューターです。今日の調子はどうですか？",
            "Chinese": "你好！我是你的中文导师。今天感觉如何？",
            "Korean": "안녕하세요! 저는 당신의 한국어 튜터입니다. 오늘 기분이 어떠세요?"
        }
        
        return welcome_messages.get(language, f"Hello! I'm your {language} tutor. How are you today?")


def correct_user_message(message, language):
    """
    Correct the user's message in the target language, improving grammar, word choice,
    word order, and other linguistic elements.
    
    This function serves as the language correction engine for the application, taking
    user-provided text in the target language and returning a corrected version that:
    1. Fixes grammatical errors
    2. Suggests better word choices or phrasing
    3. Corrects word order, conjugations, and other language-specific elements
    4. Translates the message if sent in English instead of the target language
    
    The function implements two methods for correction:
    - Direct API call to Gemini (primary method)
    - LangChain integration (fallback method)
    
    NOTE: This function is critical for the language learning experience as it provides
    immediate feedback on the user's message quality.
    
    Args:
        message (str): The user's original message in the target language (or English)
        language (str): The target language for correction (e.g., "Spanish")
    
    Returns:
        str: The corrected message with proper grammar and word choice, or the original 
             message if correction fails or the API key is missing
    """
    api_key = GEMINI_API_KEY
    
    if not api_key or not message:
        return message
    
    try:
        # Prompt for correcting user input
        system_message = f"""You are a language tutor. Correct this {language} message from a learner: "{message}"
        
        If the message is in English but should be in {language}, translate it.
        If the message is in {language} but has errors, correct them.
        Provide ONLY the corrected text with no explanations.
        If the message is already perfect, return the exact same message.
        
        For example:
        - Input: "Yo soy un estudiante de español y quero aprender"
        - Output: "Yo soy un estudiante de español y quiero aprender"
        """
        
        # Try direct API call first
        try:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')
            result = model.generate_content(system_message).text
            logger.info("Used direct API call for message correction")
            
            # If the result is empty or too long, return the original
            if not result or len(result) > len(message) * 2:
                return message
                
            return result.strip()
            
        except Exception as e:
            logger.warning(f"Direct API failed for message correction: {str(e)}")
            
            # Fallback to LangChain
            llm = ChatGoogleGenerativeAI(
                model="gemini-1.5-flash", 
                api_key=api_key,
                temperature=0.1  # Low temperature for more predictable corrections
            )
            
            result = llm.invoke([SystemMessage(content=system_message)])
            
            if hasattr(result, 'content'):
                corrected = result.content.strip()
            else:
                corrected = str(result).strip()
                
            # If the result is empty or too long, return the original
            if not corrected or len(corrected) > len(message) * 2:
                return message
                
            return corrected
            
    except Exception as e:
        logger.error(f"Error correcting message: {str(e)}")
        return message  # Return original message on error

def generate_response(message, language, vocabulary=None):
    """
    Generate a response from Gemini based on the user's message
    in the specified language, restricted to the provided vocabulary.
    
    This is the core conversation function of the application. It:
    1. Maintains conversation state between messages using session-based memory
    2. Restricts vocabulary to user-defined word lists when provided
    3. Ensures responses are appropriate for language learners
    4. Handles conversation continuity and context
    
    The function uses sophisticated prompt engineering to:
    - Limit vocabulary complexity to beginner level
    - Ensure responses end with questions to maintain conversation flow
    - Adapt tone and complexity based on the learner's level
    - Restrict vocabulary to user-selected lists when specified
    
    Multiple fallback mechanisms ensure robust operation even if certain API 
    calls fail, with logging at each step for debugging.
    
    Args:
        message (str): The user's message in the target language
        language (str): The target language for conversation (e.g., "Spanish")
        vocabulary (list, optional): List of words/phrases to restrict responses to.
                                    If provided, the AI will only use these words.
    
    Returns:
        str: AI-generated conversational response in the target language
             or an error message if generation fails
    """
    api_key = GEMINI_API_KEY
    if not api_key:
        logger.error("Gemini API key not found")
        return "Error: API key not configured. Please contact the administrator."
    
    # Add debug logging to see what API key is being used (partially masked for security)
    masked_key = api_key[:4] + '*' * (len(api_key) - 8) + api_key[-4:] if len(api_key) > 8 else '****'
    logger.debug(f"Using API key: {masked_key}")
    
    try:
        # CONVERSATION MEMORY MANAGEMENT
        # ==============================
        # This section handles maintaining conversation context between messages
        
        # Get a unique conversation ID from session
        # If no session ID exists, use 'guest' as a fallback identifier
        conversation_id = session.get('session_id', 'guest')
        
        # Create or retrieve conversation memory for this user
        # Each conversation gets its own memory instance to maintain separate chat contexts
        if conversation_id not in conversation_memories:
            # Initialize a new memory instance for first-time users
            # LangChain's ConversationBufferMemory stores conversation history as message objects
            conversation_memories[conversation_id] = ConversationBufferMemory(return_messages=True)
        
        # Get the memory object for this conversation to use later
        memory = conversation_memories[conversation_id]
        
        # PROMPT ENGINEERING FOR LANGUAGE TUTORING
        # =======================================
        # Two different system prompts are used based on whether a vocabulary list is provided:
        # 1. Restricted vocabulary mode: Forces the AI to use only words from the user's vocabulary list
        # 2. General beginner mode: Uses simpler language but without specific word restrictions
        
        if vocabulary and len(vocabulary) > 0:
            # VOCABULARY-RESTRICTED MODE
            # This specialized prompt restricts the AI to using only words from the user's vocabulary list
            # This is a key feature that allows users to practice with specific word sets they're learning
            system_message = f"""You are an engaging, conversational language tutor helping someone learn {language}.
            
            CRITICAL VOCABULARY RESTRICTIONS:
            1. STRICTLY limit your vocabulary to ONLY these words/phrases: {', '.join(vocabulary)}.
            2. If you absolutely need words outside this list, use only the most basic, common words a beginner would know.
            3. Prioritize simple sentence structures over complex ones.
            4. Use extremely basic grammar patterns that beginner students would understand.
            5. Repeat vocabulary from the list frequently to reinforce learning.
            
            IMPORTANT CONVERSATION INSTRUCTIONS:
            1. Always respond in {language}.
            2. Keep responses very short (2-3 sentences only).
            3. Use natural but extremely simplified language.
            4. Always end with a simple question to keep the conversation going.
            5. Avoid idiomatic expressions or complex conjugations.
            
            Your goal is to create a comfortable, basic conversation that builds confidence with limited vocabulary.
            """
        else:
            # GENERAL BEGINNER MODE
            # This prompt doesn't restrict specific vocabulary but ensures language is kept simple
            # and appropriate for beginning language learners (A1-A2 level)
            system_message = f"""You are an engaging, conversational language tutor helping someone learn {language}.
            
            IMPORTANT INSTRUCTIONS:
            1. Always respond in {language}.
            2. Use only basic, common vocabulary suitable for beginners (A1-A2 level).
            3. Keep responses very short (2-3 sentences only).
            4. Use simple sentence structures with basic grammar patterns.
            5. Always end with a question to maintain conversation.
            6. Avoid complex conjugations, idioms, or advanced vocabulary.
            
            Your goal is to make the conversation accessible for beginners while being engaging.
            """
        
        # Initialize the language model with appropriate parameters
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash", 
            api_key=api_key,
            temperature=0.7,
            top_p=0.95,
            max_tokens=1024,
        )
        
        # Get chat history
        history = memory.load_memory_variables({}).get("history", [])
        
        # Instead of using message objects directly, we'll build a simple list
        # Create a list of message dictionaries for the API
        messages = [
            {"role": "system", "content": system_message}
        ]
        
        # Add history messages if any
        if history:
            for msg in history:
                if hasattr(msg, 'type') and hasattr(msg, 'content'):
                    role = "user" if msg.type == "human" else "assistant"
                    messages.append({"role": role, "content": msg.content})
        
        # Add the current user message
        messages.append({"role": "user", "content": message})
        
        logger.debug(f"Sending direct message to Gemini for language: {language}")
        
        # Create proper message objects for the API
        proper_messages = []
        
        # Add system message
        proper_messages.append(SystemMessage(content=system_message))
        
        # Add history messages if any
        if history:
            proper_messages.extend(history)
        
        # Add the current user message
        proper_messages.append(HumanMessage(content=message))
        
        # Make a direct call to the model with the proper message objects
        try:
            result = llm.invoke(proper_messages)
            
            # Extract the content from the result
            if hasattr(result, 'content'):
                response = result.content
            else:
                response = str(result)
                
        except Exception as e:
            logger.error(f"Error in direct API call: {str(e)}")
            # Try backup approach with simplified parameters
            try:
                # Simplified approach without using message objects
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel('gemini-1.5-flash')
                response = model.generate_content(message).text
                logger.info("Used fallback direct API call method")
            except Exception as e2:
                logger.error(f"Both API approaches failed: {str(e2)}")
                response = f"Error: Could not generate response. {str(e)}"
        
        # Save current exchange to memory
        memory.save_context({"input": message}, {"output": response})
        
        # Log and return the response
        if response:
            logger.debug(f"Received response from Gemini: {response[:100] if isinstance(response, str) else 'non-string response'}...")
            
            # Ensure the response is a string
            if isinstance(response, str):
                return response.strip()
            else:
                return str(response)
        else:
            logger.error("Empty response received from language model")
            return "Sorry, I couldn't generate a response. Please try again."
    
    except Exception as e:
        logger.error(f"Error generating response with LangChain: {str(e)}")
        if "invalid api key" in str(e).lower():
            return "Error: The API key appears to be invalid. Please contact the administrator."
        return f"Error: {str(e)}"

def translate_single_word(word, language):
    """
    Translate a single word or short phrase from the specified language to English.
    
    This function is used for the click-to-translate feature that allows users
    to get instant translations of individual words within chat messages. It provides
    not just the translation but also a brief grammatical explanation.
    
    The response format is specifically designed to be concise and educational,
    containing the English translation and a very brief explanation of the word's 
    meaning or grammatical role.
    
    Two implementation methods are used:
    1. Direct Gemini API call (primary method)
    2. LangChain-based call (fallback method)
    
    Args:
        word (str): The word or short phrase to translate (in the target language)
        language (str): The source language (e.g., "Spanish")
    
    Returns:
        str: The English translation with brief explanation in the format:
             "Translation: [english] - [brief explanation]"
    """
    api_key = GEMINI_API_KEY
    if not api_key:
        logger.error("Gemini API key not found")
        return "Error: API key not configured. Please contact the administrator."
    
    try:
        # Create a direct and simple prompt for translation
        system_message = f"""Translate this {language} word or phrase to English: '{word}'
        
        Provide only:
        1. The English translation (1-3 words)
        2. A very brief explanation (5-10 words)
        
        Format: "Translation: [english] - [brief explanation]"
        Example: "Translation: house - a building for human habitation"
        Keep it very concise."""
        
        # Try using direct API first for fast response
        try:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(system_message).text
            logger.info("Used direct API call for word translation")
            return response.strip()
            
        except Exception as direct_err:
            logger.warning(f"Direct API call failed for translation: {str(direct_err)}")
            
            # Fall back to LangChain implementation
            llm = ChatGoogleGenerativeAI(
                model="gemini-1.5-flash", 
                api_key=api_key,
                temperature=0.1  # Lower temperature for more predictable translation
            )
            
            result = llm.invoke([SystemMessage(content=system_message)])
            
            # Extract the result from the response
            if hasattr(result, 'content'):
                return result.content.strip()
            else:
                return str(result).strip()
            
    except Exception as e:
        logger.error(f"Error translating word: {str(e)}")
        return f"Error translating '{word}'. Please try again."

def generate_analysis(message, language):
    """
    Generate a simplified linguistic analysis of the provided message in the target language.
    
    This function powers the "Analyze" feature, providing in-depth linguistic breakdowns
    for language learners. It produces a formatted analysis that includes:
    
    1. A complete translation of the message into English
    2. A sentence-by-sentence breakdown of the message
    3. Word-by-word analysis with grammatical roles, translations, and brief explanations
    
    The output format follows a specific structure:
    - Full English translation at the top
    - Each sentence as a section with its own translation
    - Each word in the sentence analyzed in a bulleted list with:
      * Bolded word (in the target language)
      * Grammatical role (verb, noun, etc.)
      * Single-word English translation
      * Brief explanation prefaced by the target language word
    
    Example output structure for Spanish:
    ```
    Translation: I want to go to the store.
    
    ## Quiero ir a la tienda.
    Translation: I want to go to the store.
    * **Quiero** verb (1st person present) "want" - Quiero is the conjugated form of "querer" (to want).
    * **ir** verb (infinitive) "to go" - Ir is the infinitive form of "to go".
    * **a** preposition "to" - A is used to indicate direction.
    * **la** article (feminine) "the" - La is the feminine definite article.
    * **tienda** noun (feminine) "store" - Tienda refers to a shop or store.
    ```
    
    Args:
        message (str): The message to analyze in the target language
        language (str): The language of the message (e.g., "Spanish")
    
    Returns:
        str: Formatted linguistic analysis with translation and word breakdowns,
             or an error message if analysis fails
    """
    api_key = GEMINI_API_KEY
    if not api_key:
        logger.error("Gemini API key not found")
        return "Error: API key not configured. Please contact the administrator."
    
    # Add debug logging to see what API key is being used (partially masked for security)
    masked_key = api_key[:4] + '*' * (len(api_key) - 8) + api_key[-4:] if len(api_key) > 8 else '****'
    logger.debug(f"Using API key: {masked_key}")
    
    try:
        # Simplified linguistic analysis prompt with specific formatting
        system_message = f"""Analyze this {language} text: "{message}"

        Begin with the full English translation on its own line:
        
        Translation: [Full English translation]
        
        Then, split the text into sentences and analyze each sentence separately.
        
        For each sentence:
        1. Use the original {language} sentence as a heading (add ## before it)
        2. Provide an English translation for just this sentence (not in header format)
        3. Under each sentence, create a bulleted list in the following format:
           * **[Word]** [grammatical role] [single word translation] - [Brief explanation in English preceded by the {language} word]
        
        Example format:
        
        Translation: Hi! How are you?
        
        ## ¡Hola!
        Translation: Hi!
        * **Hola** greeting "hello" - Hola is a common greeting in Spanish.
        
        ## ¿Cómo estás?
        Translation: How are you?
        * **cómo** question word "how" - Cómo is used to ask about manner or condition.
        * **estás** verb (present, 2nd person) "are" - Estás is the conjugated form of "estar" for "tú".
        
        Keep all explanations brief and beginner-friendly.
        """
        
        # Try direct API call first
        try:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = model.generate_content(system_message).text
            logger.info("Used direct API call for language analysis")
            return response.strip()
            
        except Exception as e:
            logger.warning(f"Direct API failed for language analysis: {str(e)}")
            
            # Fallback to LangChain implementation
            llm = ChatGoogleGenerativeAI(
                model="gemini-1.5-flash", 
                api_key=api_key,
                temperature=0.2  # Low temperature for focused analysis
            )
            
            result = llm.invoke([SystemMessage(content=system_message)])
            
            if hasattr(result, 'content'):
                return result.content.strip()
            else:
                return str(result).strip()
            
    except Exception as e:
        logger.error(f"Error generating language analysis: {str(e)}")
        return f"Error analyzing text: {str(e)}. Please try again or with a shorter message."